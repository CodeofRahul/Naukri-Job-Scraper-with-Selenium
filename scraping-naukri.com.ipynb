{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6cddd4-f9f1-4e3f-8e25-7b599b6b2c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Using cached trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Using cached trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Using cached selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
      "Using cached trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "Using cached trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: websocket-client, h11, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: websocket-client\n",
      "    Found existing installation: websocket-client 0.58.0\n",
      "    Uninstalling websocket-client-0.58.0:\n",
      "      Successfully uninstalled websocket-client-0.58.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "Successfully installed attrs-25.1.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.29.0 trio-0.29.0 trio-websocket-0.12.2 websocket-client-1.8.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c408499-a9ce-4af3-83e2-0d60eed2e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b32660-e816-495f-b999-6a8967f409c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df25aac-0c34-4fa8-b7e5-28161daf8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukripage on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2584ed9c-e0b2-432f-9797-4d2a100e798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5cccc0-6428-48f2-8347-0b1c20533b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH, \"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")  # for link Right click on location field --> click on copy --> Copy full XPATH\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce3838b7-570a-4763-b710-a0a6f5a0488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93fbbbeb-7a75-4e15-85a7-4a9b6e635d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "923e9a2f-cfe5-41fb-9ffd-9b226e63721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to make below XPATH link\n",
    "# title_tags=driver.find_elements(By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/h2/a')\n",
    "\n",
    "# click on job title --> right click and inspect it --> double click on class element -->\"CTRL + A\" to select all --> \"CTRL + C\" to copy -->\n",
    "# \"CTRL + F\" and paste to check --> then put this link in \"[]\" --> then put \"//\" in start --> then if it is div then write div and if it is \n",
    "# span than write span --> then write \"@\" just after initial \"[\"\n",
    "\n",
    "# If this link is of parent class then to go to the tags inside of it use \"/\" just after last \"]\" and write tag if need go one step in tag again\n",
    "# write \"/\" and write tag and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f272b3f3-ad3b-44ad-877f-580a9c5d6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/h2/a')\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH, '//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\"]')\n",
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH, '//span[@class=\" comp-dtls-wrap\"]/a[1]')\n",
    "for i in company_tags:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH, '//span[@class=\"expwdth\"]')\n",
    "for i in experience_tags:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b265bb6a-e99e-4c92-8d95-8df78cabff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 40 38 40\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25d182d8-6ff4-4add-9e13-1f9b9a86fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b38d37e2-2f73-44db-b77d-13d22e8aca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist /AIML Engineer-MSys Technologies', 'Gen AI Data Scientist - GGN,HYD,BLR', 'Data Scientist', 'Data Scientist', 'Data Scientist / ML Engineer', 'Data Scientist / GenAI Specialist / AI Engineer', 'Data Scientist - March Joiners', 'Data Scientists', 'Data Scientist Sahaj Software', 'Data Scientist (Bangalore/Chennai/ Pune/Jaipur/Hyderabad /Gurugram)', 'Data Scientist - BLR/ HYD/ GGN', 'Data Scientist 1', 'Lead Data Scientist/ Machine Learning with Bigdata', 'Data Scientist, NLP + GenAI', 'Data Scientist', 'Data Scientist', 'AI Data scientist', 'Data Scientist (R Programming)', 'Data Scientist - GenAI', 'Data Scientist', 'Data Scientist /AIML Engineer-MSys Technologies', 'Gen AI Data Scientist - GGN,HYD,BLR', 'Data Scientist', 'Data Scientist', 'Data Scientist / ML Engineer', 'Data Scientist / GenAI Specialist / AI Engineer', 'Data Scientist - March Joiners', 'Data Scientists', 'Data Scientist Sahaj Software', 'Data Scientist (Bangalore/Chennai/ Pune/Jaipur/Hyderabad /Gurugram)', 'Data Scientist - BLR/ HYD/ GGN', 'Data Scientist 1', 'Lead Data Scientist/ Machine Learning with Bigdata', 'Data Scientist, NLP + GenAI', 'Data Scientist', 'Data Scientist', 'AI Data scientist', 'Data Scientist (R Programming)', 'Data Scientist - GenAI', 'Data Scientist', 'Data Scientist /AIML Engineer-MSys Technologies', 'Gen AI Data Scientist - GGN,HYD,BLR', 'Data Scientist', 'Data Scientist', 'Data Scientist / ML Engineer', 'Data Scientist / GenAI Specialist / AI Engineer', 'Data Scientist - March Joiners', 'Data Scientists', 'Data Scientist Sahaj Software', 'Data Scientist (Bangalore/Chennai/ Pune/Jaipur/Hyderabad /Gurugram)', 'Data Scientist - BLR/ HYD/ GGN', 'Data Scientist 1', 'Lead Data Scientist/ Machine Learning with Bigdata', 'Data Scientist, NLP + GenAI', 'Data Scientist', 'Data Scientist', 'AI Data scientist', 'Data Scientist (R Programming)', 'Data Scientist - GenAI', 'Data Scientist'] | ['Hybrid - Chennai, Bengaluru', 'Hyderabad, Gurugram, Bengaluru', 'Hybrid - Gurugram, Bengaluru', 'Bengaluru', 'Bengaluru', 'Bengaluru', 'Hybrid - Bengaluru, Delhi / NCR', 'Bengaluru', 'Hyderabad, Pune, Chennai, Bengaluru', 'Hybrid - Pune, Chennai, Bengaluru', 'Hybrid - Hyderabad, Gurugram, Bengaluru', 'Bengaluru', 'Remote', 'Hyderabad, Chennai, Bengaluru', 'Hybrid - Pune, Chennai, Bengaluru(Bannerghatta)', 'Hybrid - Chennai, Bengaluru', 'Bengaluru', 'Bengaluru', 'Hybrid - Noida, Pune, Bengaluru', 'Chennai, Bengaluru', 'Hybrid - Chennai, Bengaluru', 'Hyderabad, Gurugram, Bengaluru', 'Hybrid - Gurugram, Bengaluru', 'Bengaluru', 'Bengaluru', 'Bengaluru', 'Hybrid - Bengaluru, Delhi / NCR', 'Bengaluru', 'Hyderabad, Pune, Chennai, Bengaluru', 'Hybrid - Pune, Chennai, Bengaluru', 'Hybrid - Hyderabad, Gurugram, Bengaluru', 'Bengaluru', 'Remote', 'Hyderabad, Chennai, Bengaluru', 'Hybrid - Pune, Chennai, Bengaluru(Bannerghatta)', 'Hybrid - Chennai, Bengaluru', 'Bengaluru', 'Bengaluru', 'Hybrid - Noida, Pune, Bengaluru', 'Chennai, Bengaluru'] | ['MSys Technologies', 'Genpact', 'Sun Life Global Solutions', 'Siemens', 'Rarr Technologies', 'Apnatime Tech', 'Virtusa', 'Sahaj Retail Limited', 'Altimetrik', 'Genpact', 'Paypal', 'Atyeti', 'Tiger Analytics', 'Cloudbc Labs', 'EdgeVerve Systems', 'Qualitest', 'Naukri E-hire Campaign', 'EXL', 'Xoom', 'MSys Technologies', 'Genpact', 'Sun Life Global Solutions', 'Siemens', 'Rarr Technologies', 'Apnatime Tech', 'Virtusa', 'Sahaj Retail Limited', 'Altimetrik', 'Genpact', 'Paypal', 'Atyeti', 'Tiger Analytics', 'Cloudbc Labs', 'EdgeVerve Systems', 'Qualitest', 'Naukri E-hire Campaign', 'EXL', 'Xoom'] | ['5-10 Yrs', '6-11 Yrs', '5-10 Yrs', '8-13 Yrs', '5-10 Yrs', '5-10 Yrs', '4-9 Yrs', '6-11 Yrs', '7-12 Yrs', '5-10 Yrs', '6-11 Yrs', '5-10 Yrs', '6-11 Yrs', '4-7 Yrs', '3-8 Yrs', '8-13 Yrs', '12-14 Yrs', '5-10 Yrs', '4-9 Yrs', '7-10 Yrs', '5-10 Yrs', '6-11 Yrs', '5-10 Yrs', '8-13 Yrs', '5-10 Yrs', '5-10 Yrs', '4-9 Yrs', '6-11 Yrs', '7-12 Yrs', '5-10 Yrs', '6-11 Yrs', '5-10 Yrs', '6-11 Yrs', '4-7 Yrs', '3-8 Yrs', '8-13 Yrs', '12-14 Yrs', '5-10 Yrs', '4-9 Yrs', '7-10 Yrs']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{job_title} | {job_location} | {company_name} | {experience_required}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b658e1a4-68cb-4773-8ffb-eff9abb4920c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m:job_title, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m'\u001b[39m:job_location, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany_name\u001b[39m\u001b[38;5;124m'\u001b[39m:company_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperience\u001b[39m\u001b[38;5;124m'\u001b[39m:experience_required})\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':job_title, 'Location':job_location, 'Company_name':company_name, 'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91fbdd9-157f-46b4-a498-73221ddd7c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024723d-af7d-41ff-9518-dd8fe9337d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151282a7-e180-433d-bdea-de78621feef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf4334-7fc0-482f-94a8-e3e1ad7c60b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e29d051-4a6d-4d54-9f6a-4210fa289d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"299415f4ff441a154bd048c8d7e7f98e\", element=\"f.2F8943C94851CF80F96ACFE4E57A4721.d.6AF9E59C87A26D7C62565470A52BCEFC.e.7829\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"299415f4ff441a154bd048c8d7e7f98e\", element=\"f.2F8943C94851CF80F96ACFE4E57A4721.d.6AF9E59C87A26D7C62565470A52BCEFC.e.7870\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"299415f4ff441a154bd048c8d7e7f98e\", element=\"f.2F8943C94851CF80F96ACFE4E57A4721.d.6AF9E59C87A26D7C62565470A52BCEFC.e.7918\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"299415f4ff441a154bd048c8d7e7f98e\", element=\"f.2F8943C94851CF80F96ACFE4E57A4721.d.6AF9E59C87A26D7C62565470A52BCEFC.e.8022\")>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fetch the url\n",
    "url = driver.find_elements(By.XPATH,'//a[@class=\"title \"]')\n",
    "url[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c70851db-a0e8-47e0-8e89-4d304b267db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/job-listings-data-scientist-aiml-engineer-msys-technologies-msys-technologies-chennai-bengaluru-5-to-10-years-030325010444\n",
      "https://www.naukri.com/job-listings-gen-ai-data-scientist-ggn-hyd-blr-genpact-hyderabad-gurugram-bengaluru-6-to-11-years-151124006761\n",
      "https://www.naukri.com/job-listings-data-scientist-sun-life-global-solutions-gurugram-bengaluru-5-to-10-years-131124010229\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in url[0:4]:   # lets provide range to print only top 4 data\n",
    "    print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e94e479a-c567-4955-ab1c-7e8801450aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45b103b8-ab9e-4832-86de-aa4686b68dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of first 3 pages\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "for page in range (start, end):\n",
    "    titles=driver.find_elements(By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/h2/a')\n",
    "    for i in titles:\n",
    "        job_titles.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH, '/html/body/div/div/main/div[1]/div[2]/div[3]/div/a[2]/span')  # to scrape data from page 1 to 3  # right click on Next button --> copy --> copy full XPATH\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a11bbf6f-130a-46d3-9c10-2e10eb7d23b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2785dabd-66b0-4613-9cb3-e29d2b12ca0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist /AIML Engineer-MSys Technologies',\n",
       " 'Gen AI Data Scientist - GGN,HYD,BLR',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / ML Engineer',\n",
       " 'Data Scientist / GenAI Specialist / AI Engineer',\n",
       " 'Data Scientist - March Joiners',\n",
       " 'Data Scientists',\n",
       " 'Data Scientist Sahaj Software',\n",
       " 'Data Scientist (Bangalore/Chennai/ Pune/Jaipur/Hyderabad /Gurugram)',\n",
       " 'Data Scientist - BLR/ HYD/ GGN',\n",
       " 'Data Scientist 1',\n",
       " 'Lead Data Scientist/ Machine Learning with Bigdata',\n",
       " 'Data Scientist, NLP + GenAI',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'AI Data scientist',\n",
       " 'Data Scientist (R Programming)',\n",
       " 'Data Scientist - GenAI',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - L3',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / Machine Learning Engineer',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / Machine Learning Engineer',\n",
       " 'Data Scientist / Machine Learning Engineer',\n",
       " 'Data Scientist-Artificial Intelligence',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist-Artificial Intelligence',\n",
       " 'Data Scientist 1',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist ( Contractual )',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist- Python, AWS, Gen AI',\n",
       " 'Data scientist & Generative AI',\n",
       " 'Simulation Expert (Data Scientist) || Bangalore',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Marketing Data Scientist & AI Professional',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist-Artificial Intelligence',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist – Generative AI, LLM, Machine Learning']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5245d-b70f-4bb0-9ca8-f416e9037bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
